# Import database module.
from google.cloud import bigquery
import os
import requests
from requests.auth import AuthBase
from Crypto.Hash import HMAC
from Crypto.Hash import SHA256
from datetime import datetime
from dateutil.tz import tzlocal
import sqlalchemy
import json
import time
import pg8000

# Class to perform HMAC encoding
class AuthHmacMetosGet(AuthBase):
    # Creates HMAC authorization header for Metos REST service GET request.
    def __init__(self, apiRoute, publicKey, privateKey):
        self._publicKey = publicKey
        self._privateKey = privateKey
        self._method = 'GET'
        self._apiRoute = apiRoute

    def __call__(self, request):
        dateStamp = datetime.utcnow().strftime('%a, %d %b %Y %H:%M:%S GMT')
        print("timestamp: ", dateStamp)
        request.headers['Date'] = dateStamp
        msg = (self._method + self._apiRoute + dateStamp + self._publicKey).encode(encoding='utf-8')
        h = HMAC.new(self._privateKey.encode(encoding='utf-8'), msg, SHA256)
        signature = h.hexdigest()
        request.headers['Authorization'] = 'hmac ' + self._publicKey + ':' + signature
        return request


# Endpoint of the API, version for example: v1
apiURI = 'https://api.fieldclimate.com/v2'

# HMAC Authentication credentials
publicKey = '77e2e9905af05cca7b21e957dc3b481ae8a03d4922966d8d'
privateKey = 'afa04ee35a5c650fb55f4181b572ace3c3b98d7d7e196526'

# Service/Route that you wish to call
#apiRoute = '/user'

STATION_IDS=["0320D955","0320D956"]
DATA_GROUP="raw"
TIME_PERIOD="1h"
#apiRoute = f'/station/{STATION_ID}'
#apiRoute= f'/data/{STATION_ID}/{DATA_GROUP}/last/{TIME_PERIOD}'
#apiRoute= '/view/predefined/0320D955/from/1638456310/to/1638542710'

# CLOUD SQL variables
db_user = os.environ.get("DB_USER")
db_pass = os.environ.get("DB_PASS")
db_name = os.environ.get("DB_NAME")
db_socket_dir = os.environ.get("DB_SOCKET_DIR", "/cloudsql")
instance_connection_name = os.environ.get("INSTANCE_CONNECTION_NAME")
db_hostname=os.environ.get("DB_HOST")
db_port=os.environ.get("DB_PORT")
temp_insert="INSERT INTO public.mediciones(id_dispositivo, tipo, valor, unidad, fechamuestreo,aplicacion_id) VALUES (:id_dispositivo,:tipo,:valor,:unidad,:fechaMuestreo,:aplicacion_id)"

db_config = {
        # [START cloud_sql_postgres_sqlalchemy_limit]
        # Pool size is the maximum number of permanent connections to keep.
        "pool_size": 5,
        # Temporarily exceeds the set pool_size if no connections are available.
        "max_overflow": 2,
        # The total number of concurrent connections for your application will be
        # a total of pool_size and max_overflow.
        # [END cloud_sql_postgres_sqlalchemy_limit]

        # [START cloud_sql_postgres_sqlalchemy_backoff]
        # SQLAlchemy automatically uses delays between failed connection attempts,
        # but provides no arguments for configuration.
        # [END cloud_sql_postgres_sqlalchemy_backoff]

        # [START cloud_sql_postgres_sqlalchemy_timeout]
        # 'pool_timeout' is the maximum number of seconds to wait when retrieving a
        # new connection from the pool. After the specified amount of time, an
        # exception will be thrown.
        "pool_timeout": 30,  # 30 seconds
        # [END cloud_sql_postgres_sqlalchemy_timeout]

        # [START cloud_sql_postgres_sqlalchemy_lifetime]
        # 'pool_recycle' is the maximum number of seconds a connection can persist.
        # Connections that live longer than the specified amount of time will be
        # reestablished
        "pool_recycle": 1800,  # 30 minutes
        # [END cloud_sql_postgres_sqlalchemy_lifetime]
    }

# Connection functions for CLOUD SQL
def getConnection():
  if os.environ.get("DB_HOST"):
      return getTCPConnection()
  return getUnixConnection() 

def getUnixConnection():

  db = sqlalchemy.create_engine(
                sqlalchemy.engine.url.URL.create(
                    drivername="postgresql+pg8000",
                    username=db_user,
                    password=db_pass,
                    database=db_name,
                    query={
                        "unix_sock": "{}/{}/.s.PGSQL.5432".format(
                            db_socket_dir,
                            instance_connection_name)
                    }
                ),
                **db_config
            )
  return db
    
def getTCPConnection():
    db = sqlalchemy.create_engine(
        sqlalchemy.engine.url.URL.create(
            drivername="postgresql+pg8000",
            username=db_user,
            password=db_pass,
            host=db_hostname,
            port=db_port,
            database=db_name
        ),
        **db_config
    )
    return db

def getMedidas(json):
    print("getMedidas")
    values=json["data"]
    list_res=[]
    for val in values:
        tipo=val["name"]
        fechaMuestreo=json["dates"][0]
        unidad=val["unit"]
        aplicacion_id="climatedata"
        
        if "aggr" in val:
            argumentos=val["aggr"]
            for arg in argumentos:
                res={}
                res["tipo"]=tipo+" "+arg
                valores=val["values"]
                res["valor"]=valores[arg][0]
                res["unidad"]=unidad
                res["fechaMuestreo"]=fechaMuestreo
                res["aplicacion_id"]=aplicacion_id
                list_res.append(res)
        #else:
            #res={}
            #res["tipo"]=tipo
            #valores=val["values"]
            #res["valor"]=valores["result"][0]
            #res["unidad"]=unidad
            #res["fechaMuestreo"]=fechaMuestreo
            #res["aplicacion_id"]=aplicacion_id
            #list_res.append(res)
        
    return list_res



def insertdata(data,json):
    try:

        #CLOUD SQL INSERTS (POSTGRES)

        db=getConnection()
        measures=getMedidas(json)
        print("Medidas: ", measures)
        try:
            if(len(measures)>0):
                for temp in measures:
                    with db.connect() as db_conn:
                        insert_stmt = sqlalchemy.text(temp_insert,)
                        db_conn.execute(insert_stmt,
                            id_dispositivo=data["station"],
                            tipo=temp["tipo"],
                            valor=temp["valor"],
                            unidad=temp["unidad"],
                            fechaMuestreo=temp["fechaMuestreo"],
                            aplicacion_id=temp["aplicacion_id"])
                print("New SQL Insertions done")
        except Exception as e:
            print("ERROR: ", e)
            pass

        #SEND TO BIG QUERY

        client=bigquery.Client()
        table_id = 'sensordata.explotacionsensor'
        
        rows_to_insert=[]
        for element in json["data"]:
            name=element["name"]
            sensor_type=element["type"]
            unit=element["unit"]
            if "aggr" in element:
                for val in element["aggr"]:    
                    values={}  
                    values["An8_Fact"]=0
                    values["An8_Granja"]=0
                    values["An8_Ubicacion"]=0
                    values["Nave"]=0
                    values["Corral"]=0
                    values["ID_Sensor"]=data["station"]
                    values["Tipo_Sensor"]=name+"_"+val
                    values["Id_Dispositivo"]=0
                    values["Tipo_Dispositivo"]="Estacion Meteorologica"
                    values["Tipo_Unidad"]=unit
                    values["ValorMin"]=0
                    values["ValorMax"]=0
                    values["Long"]=0
                    values["Lat"]=0
                    values["FechaMuestreo"]=json["dates"][0]+" UTC"
                    values["ValorMuestreo"]=element['values'][val][0]
                    values["FechaAltaSensor"]=json["dates"][0]+" UTC"
                    values["FechaBajaSensor"]=None
                    values["RSSI"]=0
                    values["Aplicacion"]="FieldClimate"
                    rows_to_insert.append(values)      
                
            else:
                if len(element['values']) > 0:
                    if element['values']['result'][0] != None:
                        values={}  
                        values["An8_Fact"]=0
                        values["An8_Granja"]=0
                        values["An8_Ubicacion"]=0
                        values["Nave"]=0
                        values["Corral"]=0
                        values["ID_Sensor"]=data["station"]
                        values["Tipo_Sensor"]=name
                        values["Id_Dispositivo"]=0
                        values["Tipo_Dispositivo"]="Estacion Meteorologica"
                        values["Tipo_Unidad"]=unit
                        values["ValorMin"]=0
                        values["ValorMax"]=0
                        values["Long"]=0
                        values["Lat"]=0
                        values["FechaMuestreo"]=json["dates"][0]+" UTC"
                        values["ValorMuestreo"]=element['values']['result'][0]
                        values["FechaAltaSensor"]=json["dates"][0]+" UTC"
                        values["FechaBajaSensor"]=None
                        values["RSSI"]=0
                        values["Aplicacion"]="FieldClimate"
                        rows_to_insert.append(values)


        errors = client.insert_rows_json(table_id,rows_to_insert)
        if errors == []:
            print('New rows have been added.')
        else:
            print(f'Encountered errors while inserting rows: {errors}')   
        
        return True

    except Exception as err:
        print(f"Error: Unexpected {err=}, {type(err)=}")

def request_data(request):
    
    try:
        to_ = time.time()
        from_ = time.time() - 900 # 900 = 15 min
        for station in STATION_IDS:
            apiRoute = f'/data/{station}/raw/from/{from_}/to/{to_}'
            auth = AuthHmacMetosGet(apiRoute, publicKey, privateKey)
            response = requests.get(apiURI+apiRoute, headers={'Accept': 'application/json'}, auth=auth)
            json=response.json()
            data={}
            data["station"]=station
            print("inserting Data")
            print(json)
            insertdata(data,json)
        return "Rows inserted"

    except Exception as err:
        print(f"Error: Unexpected {err=}, {type(err)=}")